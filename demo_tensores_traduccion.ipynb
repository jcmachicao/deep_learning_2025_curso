{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/8N+PtzPeF+JsB1JasAKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcmachicao/deep_learning_2025_curso/blob/main/demo_tensores_traduccion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3zjScQNjH-z"
      },
      "outputs": [],
      "source": [
        "# Toy RNN forward pass (tiny sizes) to illustrate input_size=4, hidden_size=6, output_size=10\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from math import exp\n",
        "\n",
        "# For reproducibility\n",
        "rng = np.random.default_rng(42)\n",
        "\n",
        "# Sizes\n",
        "input_size = 4       # one-hot over 4 Spanish tokens\n",
        "hidden_size = 6      # \"ideas/context\" capacity\n",
        "output_size = 10     # English target vocab (restricted domain)\n",
        "\n",
        "# Tiny vocabularies\n",
        "src_vocab = [\"el\", \"perro\", \"corre\", \"<eos>\"]\n",
        "tgt_vocab = [\"<pad>\", \"the\", \"a\", \"dog\", \"runs\", \"in\", \"on\", \"park\", \"<eos>\", \"quickly\"]\n",
        "\n",
        "# Parameters (initialized with small values)\n",
        "Wxh = rng.normal(0, 0.3, size=(hidden_size, input_size))   # hidden from input\n",
        "Whh = rng.normal(0, 0.3, size=(hidden_size, hidden_size))  # hidden from previous hidden\n",
        "bh  = np.zeros((hidden_size,))                              # hidden bias\n",
        "\n",
        "Why = rng.normal(0, 0.3, size=(output_size, hidden_size))  # output from hidden\n",
        "by  = np.zeros((output_size,))                              # output bias\n",
        "\n",
        "def softmax(z):\n",
        "    z = z - np.max(z)\n",
        "    e = np.exp(z)\n",
        "    return e / np.sum(e)\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "# Build an input sequence: \"el perro corre <eos>\"\n",
        "sequence = [\"el\", \"perro\", \"corre\", \"<eos>\"]\n",
        "X = [np.eye(input_size)[src_vocab.index(tok)] for tok in sequence]\n",
        "\n",
        "# Forward pass\n",
        "h_prev = np.zeros((hidden_size,))\n",
        "timesteps_rows = []\n",
        "outputs_rows = []\n",
        "\n",
        "for t, x_t in enumerate(X, start=1):\n",
        "    h_t = tanh(Wxh @ x_t + Whh @ h_prev + bh)\n",
        "    logits = Why @ h_t + by\n",
        "    probs = softmax(logits)\n",
        "    pred_idx = int(np.argmax(probs))\n",
        "    pred_token = tgt_vocab[pred_idx]\n",
        "\n",
        "    # Store for inspection\n",
        "    timesteps_rows.append({\n",
        "        \"t\": t,\n",
        "        \"input_token\": sequence[t-1],\n",
        "        **{f\"h[{i}]\": h_t[i] for i in range(hidden_size)}\n",
        "    })\n",
        "\n",
        "    outputs_rows.append({\n",
        "        \"t\": t,\n",
        "        \"input_token\": sequence[t-1],\n",
        "        **{f\"p({tok})\": probs[i] for i, tok in enumerate(tgt_vocab)},\n",
        "        \"argmax_token\": pred_token\n",
        "    })\n",
        "\n",
        "    # roll hidden\n",
        "    h_prev = h_t\n",
        "\n",
        "hidden_df = pd.DataFrame(timesteps_rows)\n",
        "out_df = pd.DataFrame(outputs_rows)\n",
        "\n",
        "# Display nicely\n",
        "from caas_jupyter_tools import display_dataframe_to_user\n",
        "display_dataframe_to_user(\"Hidden states (size=6) per timestep\", hidden_df.round(4))\n",
        "display_dataframe_to_user(\"Output distribution over target vocab (size=10) per timestep\", out_df.round(4))\n",
        "\n",
        "# Also print a compact summary for quick view\n",
        "print(\"Predicted tokens by timestep:\")\n",
        "for row in outputs_rows:\n",
        "    print(f\"t={row['t']} ({row['input_token']!r}) -> {row['argmax_token']!r}\")\n"
      ]
    }
  ]
}